{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the OLLAMA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6nCollecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.0 idna-3.10 requests-2.32.3 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Daniel Adnan! It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\" : \"llama3.2\",\n",
    "    \"prompt\" : \"Hello, My name is Daniel Adnan\",\n",
    "    \"stream\" : False,\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_text = response.text\n",
    "    data = json.loads(response_text)\n",
    "    actual_response = data[\"response\"]\n",
    "    print(actual_response)\n",
    "else: \n",
    "    print(\"Error: \", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding memory to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default OLLAMA does not preserve memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any information about your identity, so I'm not aware of your name. This conversation just started, and we haven't established any connection or context about you. Would you like to tell me your name now?\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"model\" : \"llama3.2\",\n",
    "    \"prompt\" : \"What is my name?\",\n",
    "    \"stream\" : False,\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_text = response.text\n",
    "    data = json.loads(response_text)\n",
    "    actual_response = data[\"response\"]\n",
    "    print(actual_response)\n",
    "else: \n",
    "    print(\"Error: \", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1363.39s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6nRequirement already satisfied: ollama in ./.venv/lib64/python3.13/site-packages (0.4.4)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in ./.venv/lib64/python3.13/site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in ./.venv/lib64/python3.13/site-packages (from ollama) (2.10.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib64/python3.13/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib64/python3.13/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib64/python3.13/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib64/python3.13/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib64/python3.13/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib64/python3.13/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib64/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib64/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib64/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ollama import chat as ollama_chat\n",
    "\n",
    "model = 'llama3.2'\n",
    "messages = []\n",
    "# Roles\n",
    "USER = 'user'\n",
    "ASSISTANT = 'assistant'\n",
    "\n",
    "def add_history(content, role):\n",
    "    messages.append({'role': role, 'content': content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message):\n",
    "    add_history(message, USER)\n",
    "    response = ollama_chat(model=model, messages=messages, stream=False)\n",
    "    complete_message = ''\n",
    "    for line in response:\n",
    "        # Check if the line is a tuple and contains the 'message' key\n",
    "        if isinstance(line, tuple) and line[0] == 'message':\n",
    "            message_content = line[1].content\n",
    "            complete_message += message_content\n",
    "            # print(message_content, end='', flush=True)\n",
    "        # else:\n",
    "        #     print(\"Unexpected line format:\", line)\n",
    "    add_history(complete_message, ASSISTANT)\n",
    "    return complete_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think we've reached the end of the loop! You're welcome, Shadab, for chatting with you about yourself. If you ever want to talk about something else or ask me a question, I'm here to help. Otherwise, it was great playing along with your name introduction. Have a wonderful day!\n"
     ]
    }
   ],
   "source": [
    "chat_response = chat(\"Hello, my name is Shadab\")\n",
    "print(chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think we've come full circle! Your name, Shadab, has been mentioned several times throughout our conversation. If you'd like to change the subject or ask me something else, I'm here to help!\n"
     ]
    }
   ],
   "source": [
    "chat_response = chat(\"What is my name?\")\n",
    "print(chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any information about your name. I'm a conversational AI, and our conversation just started. I don't retain any personal data or knowledge about individuals. If you'd like to share your name with me, I'd be happy to chat with you!\n",
      "[{'role': 'user', 'content': 'What is my name?'}, {'role': 'assistant', 'content': \"I don't have any information about your name. I'm a conversational AI, and our conversation just started. I don't retain any personal data or knowledge about individuals. If you'd like to share your name with me, I'd be happy to chat with you!\"}]\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "chat_response = chat(\"What is my name?\")\n",
    "print(chat_response)\n",
    "print(messages)\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6nCollecting transformers\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp313-cp313-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.2.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib64/python3.13/site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib64/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.10-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib64/python3.13/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib64/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib64/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib64/python3.13/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib64/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib64/python3.13/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib64/python3.13/site-packages (from requests->transformers) (2024.12.14)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Using cached transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading torch-2.5.1-cp313-cp313-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:10\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading faiss_cpu-1.9.0.post1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fonttools-4.55.3-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.10-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.7-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached numpy-2.2.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "Downloading pillow-11.0.0-cp313-cp313-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp313-cp313-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m759.5/759.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading scipy-1.14.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading xxhash-3.5.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (267 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading multidict-6.1.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading propcache-0.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading yarl-1.18.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (339 kB)\n",
      "Installing collected packages: pytz, mpmath, xxhash, tzdata, tqdm, threadpoolctl, sympy, setuptools, safetensors, regex, pyyaml, pyparsing, pyarrow, propcache, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, MarkupSafe, kiwisolver, joblib, fsspec, frozenlist, fonttools, filelock, dill, cycler, attrs, aiohappyeyeballs, yarl, scipy, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jinja2, huggingface-hub, faiss-cpu, contourpy, aiosignal, tokenizers, scikit-learn, nvidia-cusolver-cu12, matplotlib, aiohttp, transformers, torch, datasets\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.2 attrs-24.2.0 contourpy-1.3.1 cycler-0.12.1 datasets-3.2.0 dill-0.3.8 faiss-cpu-1.9.0.post1 filelock-3.16.1 fonttools-4.55.3 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.5 jinja2-3.1.4 joblib-1.4.2 kiwisolver-1.4.7 matplotlib-3.10.0 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 numpy-2.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pandas-2.2.3 pillow-11.0.0 propcache-0.2.1 pyarrow-18.1.0 pyparsing-3.2.0 pytz-2024.2 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.4.5 scikit-learn-1.6.0 scipy-1.14.1 setuptools-75.6.0 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.5.1 tqdm-4.67.1 transformers-4.47.0 tzdata-2024.2 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets torch faiss-cpu matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add imports section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shadab/Desktop/Github Repos/RAG with OLLAMA/.venv/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the pdf file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6nRequirement already satisfied: PyMuPDF in ./.venv/lib64/python3.13/site-packages (1.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Structures and Their Algorithms: An In-depth Exploration\n",
      "Data structures and their associated algorithms form the backbone of computer science and\n",
      "programming. They enable efficient \n",
      "data storage, manipulation, and retrieval, making them indispensable tools in solving computational\n",
      "problems. This essay \n",
      "explores various data structure algorithms, delving into their definitions, properties, usage scenarios,\n",
      "and real-life applications.\n",
      "Arrays are a linear data structure consisting of elements identified by an index. They store elements\n",
      "of the same data type in \n",
      "contiguous memory locations. Arrays are characterized by their fixed size and ability to provide\n",
      "random access to elements in \n",
      "constant time using their indices. Common algorithms associated with arrays include linear search,\n",
      "binary search, bubble sort, \n",
      "and quick sort. Arrays are typically used in scenarios where data needs to be accessed directly by\n",
      "index, such as in static \n",
      "tables or matrices.\n",
      "A linked list is a linear data structure where each element, known as a node, contains a value and a\n",
      "reference to the next node. \n",
      "Unlike arrays, linked lists have a dynamic size and do not require contiguous memory allocation.\n",
      "This makes them efficient for \n",
      "insertions and deletions. Algorithms like traversal, list reversal, and loop detection are common in\n",
      "linked lists. They are ideal \n",
      "for implementing data structures like stacks, queues, or adjacency lists in graphs.\n",
      "Stacks are linear data structures that follow the Last In, First Out principle. Elements are added\n",
      "(pushed) and removed (popped) \n",
      "only from the top of the stack. They are widely used in scenarios such as function call management,\n",
      "undo operations in text editors, \n",
      "and expression evaluation. Common algorithms include balanced parentheses validation, string\n",
      "reversal, and postfix expression \n",
      "evaluation.\n",
      "Queues are linear data structures that operate on the First In, First Out principle. Elements are\n",
      "added at the rear and removed \n",
      "from the front. Queues are essential in scheduling tasks, simulations, and real-time systems.\n",
      "Algorithms like Breadth-First Search \n",
      "and task scheduling are commonly associated with queues. Variants of queues include circular\n",
      "queues, priority queues, and double-ended \n",
      "queues (deques).\n",
      "Hash tables are data structures that use a hash function to map keys to values, enabling efficient\n",
      "lookups. They provide average-case \n",
      "constant time complexity for insertions, deletions, and lookups. Hash tables are used in dictionaries,\n",
      "caches, and database indexing. \n",
      "Algorithms associated with hash tables include hashing, collision resolution, and substring search.\n",
      "Trees are hierarchical data structures consisting of nodes, where each node has a value and\n",
      "pointers to its child nodes. The topmost \n",
      "node is called the root. Trees are recursive in nature and come in various forms, including binary\n",
      "trees, binary search trees, AVL \n",
      "trees, and heaps. They are widely used in databases, file systems, and network routing. Traversal\n",
      "algorithms like in-order, pre-order, \n",
      "and post-order are commonly employed to navigate trees.\n",
      "Graphs are collections of nodes (vertices) connected by edges. They can be directed or undirected,\n",
      "weighted or unweighted. Graphs \n",
      "are versatile and are used in network topology, social media analysis, and geographical mapping.\n",
      "Common algorithms for graphs include \n",
      "Depth-First Search, Dijkstra's Algorithm, and Kruskal's Algorithm. These algorithms help in\n",
      "exploring, finding shortest paths, and \n",
      "determining minimum spanning trees.\n",
      "Heaps are specialized tree-based data structures that maintain the heap property, where parent\n",
      "nodes are either greater than or less \n",
      "than their child nodes. Heaps are commonly used to implement priority queues. Algorithms like heap\n",
      "sort, insertion, deletion, and \n",
      "merging heaps are key operations in heaps. They are ideal for solving problems that require\n",
      "priority-based processing.\n",
      "Understanding and applying data structures and their algorithms is crucial for solving computational\n",
      "problems efficiently. Each data \n",
      "structure has unique properties and is suited for specific tasks, from managing static data to\n",
      "handling dynamic relationships. Mastery \n",
      "of these tools enables developers to choose the right structure for the problem, optimizing\n",
      "performance and resource utilization.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  \n",
    "\n",
    "# Open the PDF file\n",
    "pdf_document = \"ds_algo.pdf\"\n",
    "document = fitz.open(pdf_document)\n",
    "\n",
    "all_text = \"\"\n",
    "\n",
    "for page_num in range(len(document)):\n",
    "    page = document.load_page(page_num) \n",
    "    text = page.get_text()  \n",
    "    all_text += text \n",
    "\n",
    "print(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the text (splitting by paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 0 paragraph: Data Structures and Their Algorithms: An In-depth Exploration \n",
      "\n",
      "sample: 1 paragraph: Data structures and their associated algorithms form the backbone of computer science and \n",
      "\n",
      "sample: 2 paragraph: programming. They enable efficient \n",
      "\n",
      "sample: 3 paragraph: data storage, manipulation, and retrieval, making them indispensable tools in solving computational \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the text into paragraphs (simple split by newline characters)\n",
    "def read_and_split_text(all_text):\n",
    "    \n",
    "    paragraphs = all_text.split('\\n')\n",
    "    paragraphs = [para.strip() for para in paragraphs if len(para.strip()) > 0]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "# Split the text into paragraphs\n",
    "paragraphs = read_and_split_text(all_text)\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"sample: {i} paragraph: {paragraphs[i]} \\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and indexing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DPRContextEncoderTokenizer(name_or_path='facebook/dpr-ctx_encoder-single-nq-base', vocab_size=30522, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "context_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Structures and Their Algorithms: An In-depth Exploration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2951,  5090,  1998,  2037, 13792,  1024,  2019,  1999,  1011,\n",
       "          5995,  8993,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = paragraphs[0]\n",
    "print (text)\n",
    "\n",
    "tokens_result=context_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=256)\n",
    "tokens_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding into vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPRContextEncoderOutput(pooler_output=tensor([[-2.0544e-01, -7.2211e-02, -1.2554e-01,  4.8373e-01,  6.7757e-02,\n",
       "          2.0745e-01, -1.1438e-02, -3.9053e-01, -1.8430e-01, -3.9968e-01,\n",
       "         -4.9544e-01,  2.2363e-01,  3.4093e-01,  1.4782e-01,  1.8178e-01,\n",
       "          5.1610e-01,  2.1001e-01, -1.3630e-01,  1.9358e-01, -5.2526e-01,\n",
       "         -3.0839e-01, -1.1096e-01,  1.7510e-01, -5.3886e-02,  1.5549e-01,\n",
       "         -2.1476e-01,  2.1696e-02,  4.4649e-01, -2.0951e-01, -2.0150e-02,\n",
       "         -3.0971e-01,  1.0972e-01, -1.8448e-01, -3.8305e-01,  1.6747e-01,\n",
       "         -3.9037e-03, -3.0259e-01, -1.8990e-02, -3.2050e-01, -5.1606e-01,\n",
       "          3.8579e-01,  5.0572e-01, -1.9355e-01,  4.4752e-01, -4.6883e-01,\n",
       "         -4.2403e-01, -1.4848e+00, -2.5618e-01, -6.0209e-01, -2.1537e-01,\n",
       "         -2.1714e-01,  3.3058e-01,  8.8075e-01, -2.3523e-02, -2.6663e-01,\n",
       "          3.8859e-01,  3.0427e-02, -1.8447e-01,  3.1187e-01, -1.5270e-01,\n",
       "          3.0220e-01, -1.1701e-01, -1.4114e-01,  1.3326e-01,  7.6226e-02,\n",
       "          1.8076e-01, -2.3401e-02, -1.9554e-01, -3.5387e-01, -5.0181e-03,\n",
       "          3.9580e-01, -2.2875e-01, -1.8024e-01,  4.9744e-01, -6.8243e-01,\n",
       "         -1.0439e-01,  3.5128e-01,  2.9882e-01, -1.3114e-02,  8.8584e-02,\n",
       "         -1.7596e-01,  2.6845e-01,  2.3982e-01, -2.7274e-01,  4.9646e-01,\n",
       "          4.7228e-01, -2.9384e-01,  4.5649e-01, -7.1782e-01,  6.6849e-02,\n",
       "         -1.0878e-01, -3.4583e-01,  4.2252e-01,  5.7062e-01,  4.9259e-01,\n",
       "          5.9167e-02, -9.9303e-03,  6.9558e-02,  3.7621e-01,  5.8932e-01,\n",
       "         -4.2032e-01,  5.1028e-02, -1.2000e-01, -1.2421e-01,  9.9304e-02,\n",
       "         -2.9059e-01, -5.9931e-01, -3.9553e-01, -4.5594e-01,  1.8262e-01,\n",
       "         -4.5496e-01,  5.5771e-02,  3.3860e-02, -2.0902e-01, -1.3538e-01,\n",
       "          2.8674e-01,  6.1536e-01,  1.3244e-01, -1.1414e-01,  2.4682e-01,\n",
       "          1.9246e-01,  6.5268e-01,  9.5069e-02,  3.8055e-01, -1.8487e-01,\n",
       "         -1.2227e-01,  5.5923e-01,  5.1006e-01, -1.3506e-01,  9.9290e-02,\n",
       "          7.0139e-02,  5.3293e-01, -3.0187e-01,  2.0787e-01, -1.6692e-01,\n",
       "         -1.5258e-01,  5.5811e-03,  2.0365e-01,  1.6536e-01,  1.3234e-01,\n",
       "         -7.0272e-01, -5.0057e-01,  1.1057e-03, -3.0269e-01,  2.0746e-01,\n",
       "         -4.7902e-01, -1.4419e-01, -2.8614e-01, -4.6586e-01,  2.3698e-01,\n",
       "         -2.8819e-01,  5.3232e-01, -7.5283e-01, -1.3770e-01, -2.5991e-01,\n",
       "          6.2518e-01, -2.1894e-01,  2.2679e-01,  1.7904e-01,  2.1746e-01,\n",
       "          1.3235e-02,  1.9182e-01, -4.6270e-01, -4.8286e-01, -3.3672e-01,\n",
       "         -8.4945e-01,  6.2315e-01,  2.2639e-01,  1.5675e-01, -1.4088e-02,\n",
       "         -1.4688e-01, -9.1714e-02, -3.8569e-04, -8.7463e-02,  2.5918e-01,\n",
       "          2.2250e-01,  3.1427e-01,  3.1914e-01,  1.6737e-01, -3.9886e-02,\n",
       "         -4.7608e-01, -1.3594e-01, -1.0743e-02, -5.9972e-01,  2.6967e-01,\n",
       "          9.0418e-02,  2.2641e-01,  2.8359e-01, -5.7679e-02,  2.8322e-01,\n",
       "         -3.5214e-01, -1.8295e-01,  3.4783e-01, -7.0258e-01,  7.3845e-01,\n",
       "         -2.4915e-01,  6.1682e-03,  8.3918e-01, -8.5519e-02,  1.5244e-02,\n",
       "         -8.0614e-02, -4.3855e-02, -1.3050e-01, -3.2983e-01, -1.5900e-01,\n",
       "          1.0550e-01,  2.9221e-01, -3.6684e-01, -7.8245e-01,  5.4576e-02,\n",
       "          1.1487e-01, -1.0443e-01,  2.0547e-01, -4.1837e-01,  4.4571e-01,\n",
       "          1.5602e-02, -3.4468e-01,  4.4662e-01, -3.2242e-01,  9.9805e-02,\n",
       "          1.0532e+00,  8.9493e-02,  1.3007e-01,  5.5488e-01, -3.2247e-01,\n",
       "          5.1792e-01,  5.7937e-01,  4.8942e-01,  5.3673e-01, -6.2315e-01,\n",
       "         -3.5538e-01, -1.3138e-01, -1.4545e-01, -5.2193e-01,  1.1064e-01,\n",
       "         -1.1908e-01,  1.4287e-01,  1.4436e-01,  3.7687e-01, -2.5707e-01,\n",
       "          4.1007e-02, -1.1177e-01, -1.8863e-01,  4.1652e-01,  1.0835e-01,\n",
       "         -3.6428e-01, -6.8486e-02,  2.1204e-01, -3.4615e-01, -2.2091e-01,\n",
       "         -2.8914e-01,  2.4875e-01,  1.1539e-01, -4.4308e-01, -1.4607e-01,\n",
       "         -3.6630e-01, -1.3774e-01, -3.3660e-01,  3.5426e-01,  4.5282e-01,\n",
       "         -8.8243e-02, -6.2155e-02, -2.1869e-01, -4.3851e-01,  2.6986e-01,\n",
       "         -4.2620e-01, -5.2732e-01, -1.1059e+00,  8.9780e-01,  3.8173e-01,\n",
       "          2.9563e-01,  2.0081e-03,  1.4495e-01, -1.7390e-01, -1.1634e-01,\n",
       "         -8.1580e-01,  4.4084e-01, -1.1334e-01, -5.6813e-01, -5.5155e-01,\n",
       "          3.0259e-01,  3.8730e-01,  2.5851e-01, -1.3300e-01, -3.9028e-01,\n",
       "         -4.8135e-02, -1.2190e-01, -2.7287e-01, -3.5471e-01,  6.0539e-02,\n",
       "         -2.9767e-01,  4.6287e-01, -2.5234e-01, -2.4238e-01,  3.8828e-01,\n",
       "          7.6096e-01, -3.9710e-01, -1.5921e-01, -2.1230e-02,  6.3938e-02,\n",
       "         -9.1063e-02,  4.5671e-01, -3.1348e-01, -1.1679e-01,  6.5386e-02,\n",
       "         -4.3134e-01, -3.1330e-01,  7.5144e-01, -6.2112e+00, -4.1573e-01,\n",
       "         -3.6026e-01,  6.9869e-02, -5.2457e-01,  1.2386e-02,  6.0431e-01,\n",
       "          1.8093e-01,  2.8455e-01, -6.1250e-01, -1.0543e-01,  1.8119e-01,\n",
       "         -1.9438e-01,  6.4657e-01,  3.6603e-01,  3.3532e-01,  4.7323e-01,\n",
       "          1.8273e-01,  3.5129e-01,  4.9636e-01, -2.7490e-01, -3.3631e-01,\n",
       "         -2.6685e-01,  5.8926e-02, -1.9985e-01, -2.0030e-01, -6.4690e-01,\n",
       "          6.4993e-01, -2.2744e-01, -9.7641e-02, -1.0388e-01, -7.5035e-01,\n",
       "         -3.7936e-01, -1.0829e-01,  1.6553e-01,  2.8108e-01,  1.5612e-01,\n",
       "          2.9546e-01,  3.8572e-01, -7.3717e-02, -2.9391e-02,  2.8133e-01,\n",
       "          3.4534e-02,  2.1615e-01,  4.0264e-01, -3.7947e-01, -2.4608e-01,\n",
       "         -5.2043e-02,  2.3244e-01,  2.9781e-01, -3.5821e-01,  2.5558e-01,\n",
       "          6.4936e-01, -2.4365e-01,  1.9958e-01, -3.8553e-01,  6.9978e-01,\n",
       "         -1.8116e-01, -3.8550e-01,  2.4705e-01,  7.9074e-01, -6.4381e-01,\n",
       "          6.7312e-01, -7.3534e-01, -3.0026e-01,  1.1734e-01, -5.2534e-01,\n",
       "         -2.3453e-01, -2.3016e-01, -1.2061e-01, -2.1964e-01,  4.9808e-01,\n",
       "          4.0094e-02, -4.3770e-01,  4.6665e-01, -3.5774e-01,  2.6620e-01,\n",
       "         -1.6097e-01,  3.0662e-01, -1.9302e-01, -5.0826e-01, -3.6944e-01,\n",
       "         -1.6522e-01,  3.1529e-01, -2.3808e-01, -7.0142e-01, -4.1186e-03,\n",
       "         -3.9235e-01, -6.9369e-01, -1.7479e-02,  6.1036e-01, -4.5624e-01,\n",
       "          2.4011e-01,  7.6883e-01,  7.7721e-01,  4.5277e-01,  4.0584e-01,\n",
       "          1.3387e-01,  5.5357e-01, -3.3386e-01,  5.6578e-01, -2.6964e-01,\n",
       "         -1.6368e-01, -3.5922e-01, -2.1354e-02, -1.5802e-02, -1.3078e-01,\n",
       "          3.7532e-01,  4.3982e-01, -3.9530e-01, -1.4717e-01,  4.9650e-01,\n",
       "         -4.2369e-01, -1.2624e-01,  2.0470e-01,  4.8128e-01, -4.9424e-01,\n",
       "          8.1081e-02,  5.5787e-01, -7.1650e-02, -2.5535e-01,  2.0988e-01,\n",
       "          2.5439e-01,  4.7166e-01,  5.3977e-01, -2.1552e-01,  4.6820e-01,\n",
       "          3.1221e-01, -1.2399e-01, -1.3290e-01,  1.6311e-01,  3.5716e-01,\n",
       "          1.2565e-01, -2.0486e-01,  4.6734e-01, -6.3780e-01, -1.2744e-01,\n",
       "         -1.0526e-01, -4.7982e-02, -1.3801e-01,  3.8614e-01,  5.1817e-02,\n",
       "          1.9119e-01,  1.8632e-01,  3.5220e-01,  1.3278e-01, -2.1816e-01,\n",
       "          4.4036e-01, -1.0555e-01,  3.2332e-01, -3.4176e-01, -8.3363e-01,\n",
       "          5.4354e-01, -3.9404e-01,  3.9619e-02, -2.3641e-01,  9.0425e-02,\n",
       "         -2.0330e-01,  4.0276e-01, -9.8590e-02,  4.4896e-01,  1.3229e-01,\n",
       "         -8.3243e-01,  4.3604e-02,  8.8588e-02,  2.6682e-01, -7.1538e-01,\n",
       "         -1.3178e-02, -2.4508e-01,  1.2655e-01, -7.0969e-02, -1.5031e-01,\n",
       "         -2.4594e-01, -6.2470e-01,  1.0827e-01, -1.6263e-01,  2.0589e-01,\n",
       "          1.5359e-01, -9.6194e-02,  6.0873e-02,  3.6614e-01, -3.0148e-01,\n",
       "         -1.5957e-01,  1.0343e+00,  9.0238e-01,  1.7864e-01,  1.7260e-01,\n",
       "          2.0363e-01, -3.5981e-01,  3.0981e-01,  1.3379e-01,  1.9128e-01,\n",
       "          2.8602e-01,  3.6663e-02, -3.0696e-01, -5.5546e-03,  5.8391e-01,\n",
       "         -2.7898e-02, -4.7809e-02, -4.9626e-01,  1.8304e-03,  2.7402e-01,\n",
       "         -1.1490e-01,  5.1442e-01,  1.5540e-01, -4.9268e-01, -6.7218e-02,\n",
       "         -2.7125e-01, -3.0189e-01, -2.2147e-01, -3.3417e-01,  1.2238e-01,\n",
       "         -3.0112e-01, -2.4368e-01, -5.2506e-01,  1.5261e-01,  2.9041e-01,\n",
       "         -5.1165e-02, -7.6600e-01,  2.8050e-01,  1.9395e-01, -2.5515e-01,\n",
       "         -1.2348e-01, -1.1199e-01,  1.9676e-01,  3.0326e-01,  4.3017e-01,\n",
       "         -2.6438e-01, -8.5564e-02,  1.4941e-01, -3.8047e-01, -1.8278e-01,\n",
       "         -2.7371e-01,  1.9179e-01, -3.9954e-02, -1.2551e-01, -2.7642e-01,\n",
       "          3.1826e-01, -1.9048e-01,  3.6080e-02,  4.3736e-01,  3.4620e-01,\n",
       "         -2.3785e-01, -3.1137e-01,  9.9833e-02,  4.6732e-01,  1.2636e-01,\n",
       "         -1.1444e-02, -5.3335e-01, -2.7710e-01,  3.8245e-01, -1.2974e-01,\n",
       "         -3.4523e-01, -2.2669e-01,  8.0371e-01,  5.6468e-01, -1.4482e-01,\n",
       "         -6.0178e-01, -8.8042e-02,  1.5528e-01,  3.0852e-02, -4.3917e-01,\n",
       "         -5.9678e-01, -1.5877e-01,  3.3061e-01,  3.7409e-01, -3.4407e-01,\n",
       "         -1.9637e-01,  1.0733e-01, -1.4862e-01, -5.8822e-01, -7.4963e-02,\n",
       "          5.2674e-02,  4.7380e-01, -1.5586e-01,  2.1435e-01,  9.3566e-03,\n",
       "         -5.2381e-02, -3.1945e-01, -1.1707e-01, -3.9468e-01,  1.6050e-01,\n",
       "         -6.7988e-02, -3.6558e-01,  3.6126e-01,  1.3598e-01,  6.8346e-02,\n",
       "          1.6113e-01,  2.0197e-01, -1.4410e-02, -5.9554e-02,  2.7892e-02,\n",
       "         -3.1897e-01,  9.3834e-02,  2.4025e-01,  1.0027e-01,  5.2240e-01,\n",
       "         -1.3834e-01,  2.9983e-01,  5.5693e-02, -4.3301e-01,  6.9314e-01,\n",
       "          5.5248e-01, -7.0782e-01,  8.9653e-01,  1.1469e-01,  2.3511e-01,\n",
       "          1.8457e-01, -3.5145e-02,  4.2833e-02,  1.7656e-01,  3.4799e-01,\n",
       "         -2.5467e-01,  7.5191e-01, -4.7604e-01, -1.6420e-01,  4.4906e-01,\n",
       "         -5.4634e-01,  6.9246e-01,  2.8748e-01, -2.5394e-02,  5.0346e-01,\n",
       "          3.2944e-01,  5.1657e-02, -4.5793e-01,  4.7690e-01, -3.0304e-01,\n",
       "          9.2005e-02, -1.7354e-01,  1.6663e-01,  1.9998e-01,  7.2761e-01,\n",
       "         -1.9752e-01,  3.8809e-01, -2.1627e-01,  1.7582e-01,  2.4931e-01,\n",
       "         -4.7410e-01,  1.0108e-01,  2.4722e-02,  2.3546e-01,  2.8875e-01,\n",
       "         -2.1042e-01,  2.7075e-01, -7.4862e-01,  3.1849e-01,  1.0979e-01,\n",
       "          1.8234e-01, -6.9038e-01,  5.9089e-01,  4.1353e-01,  1.3516e-01,\n",
       "          4.0285e-01, -4.5556e-01, -1.8486e-01, -3.1596e-01,  1.7248e-01,\n",
       "         -1.4330e-01,  9.7340e-02,  6.2167e-02,  1.4049e-01,  8.5790e-01,\n",
       "         -3.2598e-01,  7.6557e-02, -2.0030e-01,  2.2380e-01,  4.0316e-01,\n",
       "         -2.7960e-01,  4.7657e-01, -2.5722e-01, -2.6900e-01,  3.8378e-01,\n",
       "         -6.3502e-01,  8.4815e-02, -1.9420e-01, -9.4020e-01, -1.2328e-01,\n",
       "         -1.4915e-02,  2.0250e-01,  1.2667e-01,  3.3024e-01, -7.8988e-02,\n",
       "         -1.9972e-01, -3.6360e-01,  7.7901e-02,  8.5403e-02, -5.2343e-02,\n",
       "          5.3070e-01,  6.3914e-02, -8.5791e-02,  7.3109e-03, -4.6886e-01,\n",
       "         -5.4121e-02,  2.2604e-01, -3.5427e-01,  3.8842e-02, -3.4481e-01,\n",
       "          6.8317e-01,  2.8102e-01,  2.8100e-01, -2.1475e-01,  3.0220e-02,\n",
       "          2.7957e-01,  2.5735e-01, -4.5949e-01, -2.6939e-02, -6.3671e-01,\n",
       "         -8.4501e-02, -1.0100e+00,  1.7171e-02,  4.5807e-01, -2.2510e-01,\n",
       "         -4.5609e-01,  1.5225e-01,  8.0842e-02,  2.6524e-01,  1.1239e-01,\n",
       "         -4.0801e-03,  5.9681e-01,  1.7795e-01, -1.2708e-01, -5.6373e-01,\n",
       "          1.8499e-01,  3.3278e-01, -1.9487e-01, -2.2429e-01, -1.7793e-01,\n",
       "          3.4245e-01, -6.4453e-02,  5.0496e-02,  3.4738e-01,  7.2899e-03,\n",
       "         -4.5480e-01,  5.0117e-01,  1.5210e-01, -1.9662e-01,  1.1513e-01,\n",
       "          2.8898e-01,  4.3115e-01, -1.1250e-01, -4.5482e-01, -5.7585e-02,\n",
       "         -2.0856e-02,  4.6613e-01, -8.7140e-01,  3.6440e-01, -3.7169e-01,\n",
       "         -2.6223e-01, -6.8498e-01,  1.8411e-01,  1.1098e-01,  2.4725e-03,\n",
       "          9.1640e-03, -5.3573e-01, -7.8466e-01, -8.8883e-02,  2.5015e-01,\n",
       "         -6.5287e-01,  1.3937e-02, -2.6628e-01]], grad_fn=<SliceBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs=context_encoder(**tokens_result)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to tokenize and embed the input text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 768)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_contexts(text_list):\n",
    "    embeddings = []\n",
    "    for text in text_list:\n",
    "        inputs = context_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=256)\n",
    "        outputs = context_encoder(**inputs)\n",
    "        embeddings.append(outputs.pooler_output)\n",
    "    return torch.cat(embeddings).detach().numpy()\n",
    "\n",
    "context_embeddings = encode_contexts(paragraphs)\n",
    "context_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
